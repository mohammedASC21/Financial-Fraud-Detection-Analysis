{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f485cae",
   "metadata": {},
   "source": [
    "# Data Transform\n",
    "\n",
    "In this notebook, we will ask you a series of questions to evaluate your findings from your EDA. Based on your response & justification, we will ask you to also apply a subsequent data transformation. \n",
    "\n",
    "If you state that you will not apply any data transformations for this step, you must **justify** as to why your dataset/machine-learning does not require the mentioned data preprocessing step.\n",
    "\n",
    "The bonus step is completely optional, but if you provide a sufficient feature engineering step in this project we will add `1000` points to your Kahoot leaderboard score.\n",
    "\n",
    "You will write out this transformed dataframe as a `.csv` file to your `data/` folder.\n",
    "\n",
    "**Note**: Again, note that this dataset is quite large. If you find that some data operations take too long to complete on your machine, simply use the `sample()` method to transform a subset of your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90a38922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51003953",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions2 = pd.read_csv(\"../data/bank_transactions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b7ff243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " type              0\n",
      "amount            0\n",
      "nameOrig          0\n",
      "oldbalanceOrg     0\n",
      "newbalanceOrig    0\n",
      "nameDest          0\n",
      "oldbalanceDest    0\n",
      "newbalanceDest    0\n",
      "isFraud           0\n",
      "isFlaggedFraud    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = transactions2.isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bb9e59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud\n",
      "0    998703\n",
      "1      1297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(transactions2['isFraud'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360ca62",
   "metadata": {},
   "source": [
    "## Q1\n",
    "\n",
    "Does your model contain any missing values or \"non-predictive\" columns? If so, which adjustments should you take to ensure that your model has good predictive capabilities? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "My model doesn't contain any missing values but contain two \"non-predictive\" columns which are nameOrig and nameDest.\n",
    "\n",
    "The adjustments I should take to ensure that my model has good predictive capabilities is by removing the nameOrig and nameDest column from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdf0e9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = transactions2.drop(columns=['nameOrig', 'nameDest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "556457d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest', 'isFraud', 'isFlaggedFraud'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301be5ef",
   "metadata": {},
   "source": [
    "## Q2\n",
    "\n",
    "Do certain transaction types consistently differ in amount or fraud likelihood? If so, how might you transform the type column to make this pattern usable by a machine learning model? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "TRANSFER and CASH_OUT transactions are commonly associated with fraud and involve higher amounts.\n",
    "\n",
    "Other types like PAYMENT, DEBIT, CASH_IN doesn't assoicted with kind of fraudulent activites.\n",
    "\n",
    "I will transform the type column to make this pattern usable by a machine learning model by using One-Hot Encoding to separate the columns for each transaction type because Machine learning models canâ€™t use text directly. Therefore, I will convert it into numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa820db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.get_dummies(transactions, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa8628c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest',\n",
       "       'newbalanceDest', 'isFraud', 'isFlaggedFraud', 'type_CASH_IN',\n",
       "       'type_CASH_OUT', 'type_DEBIT', 'type_PAYMENT', 'type_TRANSFER'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b952403f",
   "metadata": {},
   "source": [
    "## Q3\n",
    "\n",
    "After exploring your data, you may have noticed that fraudulent transactions are rare compared to non-fraudulent ones. What challenges might this pose when training a machine learning model? What strategies could you use to ensure your model learns meaningful patterns from the minority class? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "The challenges would be that the model will mostly learn from the not froud data rather than the froud data since there are way more none froud data than froud data. The Metrics will also be inaccurate and misleading.\n",
    "\n",
    "The strategies that I will use is that I will balance the dataset by undersampling non-fraud which will make the froud and none froud equal to each other. For example, there are 1297 froud transections and  998703 non-froud transections which shows the diffference is too high. So I will undersample the non-froud to make it 1297 to match it with froud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e22f1422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFraud\n",
      "1    1297\n",
      "0    1297\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "fraud = transactions[transactions['isFraud'] == 1]\n",
    "non_fraud = transactions[transactions['isFraud'] == 0]\n",
    "\n",
    "# Downsample non-fraud to match fraud count\n",
    "non_fraud_downsampled = resample(non_fraud, replace=False, n_samples=len(fraud), \n",
    "                                 random_state=42)\n",
    "\n",
    "# Combine to create balanced dataset\n",
    "balanced_data = pd.concat([fraud, non_fraud_downsampled])\n",
    "\n",
    "# Shuffle the dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "print(balanced_data['isFraud'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17737e9e",
   "metadata": {},
   "source": [
    "## Bonus (optional)\n",
    "\n",
    "Are there interaction effects between variables (e.g., fraud and high amount and transaction type) that aren't captured directly in the dataset? Would it be helpful to manually engineer any new features that reflect these interactions? Apply your data transformations (if any) in the code-block below.\n",
    "\n",
    "Answer Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f48b7af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81cbfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out newly transformed dataset to your folder\n",
    "balanced_data.to_csv(\"../data/transformed_transactions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
